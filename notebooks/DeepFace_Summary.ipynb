{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <center>`Анализ библиотеки`<span style='color:red'>DeepFace</span>\n",
    "___\n",
    "\n",
    "Ссылки на `документацию`:\n",
    "\n",
    "| Описание| Ссылка|\n",
    "| - | -  |\n",
    "|Инструкция DeepFace |[*Yotube channel*](https://www.youtube.com/watch?v=WnUVYQP4h44&list=PLsS_1RYmYQQFdWqxQggXHynP1rqaYXv_E&index=2)|\n",
    "|GitHub  DeepFace| [*GitHub profile*](https://github.com/serengil/deepface)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a id=100>Содержание</a>\n",
    "- [Краткое описание библиотеки](#1)\n",
    "- [Обзор основных функций библиотеки](#2)\n",
    "    - [Верификация лица](#3)\n",
    "    - [Распознование лица](#4)\n",
    "    - [Анализ признаков embedding](#5)\n",
    "    - [Анализ аттрибутов лица](#6)\n",
    "    - [Детектирование лиц](#7)\n",
    "    - [Анализ лица в режиме реального времени](#8)\n",
    "    - [API](#9)\n",
    "- [Анализ работы библиотеки](#5)\n",
    "    - [Датасет](#6)\n",
    "    - [Анализ функций](#7)\n",
    "    - [Сохранение промежуточных данных](#8)\n",
    "    - [Датафрейм с результатами анализа](#9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <center><a id=1 >Краткое описание библиотеки</a>\n",
    "\n",
    "В библиотеке использованы решения:\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-color:#9ABAD9;border-spacing:0;}\n",
    ".tg td{background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:0px;color:#444;\n",
    "  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{background-color:#409cff;border-color:#9ABAD9;border-style:solid;border-width:0px;color:#fff;\n",
    "  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-fymr{border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-leq3{background-color:#009901;border-color:inherit;font-weight:bold;text-align:center;vertical-align:top}\n",
    ".tg .tg-kbue{background-color:#9aff99;border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-fymr\">Детектирование</th>\n",
    "    <th class=\"tg-leq3\">Распознование<br></th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-fymr\">OpenCV<br></td>\n",
    "    <td class=\"tg-kbue\">Facenet512</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-fymr\">Ssd</td>\n",
    "    <td class=\"tg-kbue\">SFace</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-fymr\">Dlib<br></td>\n",
    "    <td class=\"tg-kbue\">ArcFace</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-fymr\">MTCNN</td>\n",
    "    <td class=\"tg-kbue\">Dlib</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-fymr\">RetinaFace</td>\n",
    "    <td class=\"tg-kbue\">Facenet</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-fymr\">MediaPipe</td>\n",
    "    <td class=\"tg-kbue\">VGG-Face</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-fymr\">YoloV8</td>\n",
    "    <td class=\"tg-kbue\">OpenFace</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-fymr\">Yunet</td>\n",
    "    <td class=\"tg-kbue\">DeepID</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "Заявленная точность распознования:\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-color:#9ABAD9;border-spacing:0;}\n",
    ".tg td{background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:0px;color:#444;\n",
    "  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{background-color:#409cff;border-color:#9ABAD9;border-style:solid;border-width:0px;color:#fff;\n",
    "  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-wa1i{font-weight:bold;text-align:center;vertical-align:middle}\n",
    ".tg .tg-aznb{background-color:#ecf4ff;font-style:italic;text-align:left;vertical-align:top}\n",
    ".tg .tg-gyq4{background-color:#88CDB2;border-color:inherit;color:#062425;font-weight:bold;text-align:center;vertical-align:middle}\n",
    ".tg .tg-4qoz{background-color:#ecf4ff;border-color:inherit;text-align:left;vertical-align:middle}\n",
    ".tg .tg-uzvj{border-color:inherit;font-weight:bold;text-align:center;vertical-align:middle}\n",
    ".tg .tg-g7sd{border-color:inherit;font-weight:bold;text-align:left;vertical-align:middle}\n",
    ".tg .tg-r6x4{background-color:#ecf4ff;text-align:left;vertical-align:middle}\n",
    ".tg .tg-yla0{font-weight:bold;text-align:left;vertical-align:middle}\n",
    ".tg .tg-6t3r{font-style:italic;font-weight:bold;text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-gyq4\">Model</th>\n",
    "    <th class=\"tg-uzvj\">LFW Score</th>\n",
    "    <th class=\"tg-wa1i\">YTF Score</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-g7sd\">Facenet512</td>\n",
    "    <td class=\"tg-4qoz\">99.65%</td>\n",
    "    <td class=\"tg-r6x4\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-g7sd\">SFace</td>\n",
    "    <td class=\"tg-4qoz\">99.60%</td>\n",
    "    <td class=\"tg-r6x4\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-g7sd\">ArcFace</td>\n",
    "    <td class=\"tg-4qoz\">99.41%</td>\n",
    "    <td class=\"tg-r6x4\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-g7sd\">Dlib</td>\n",
    "    <td class=\"tg-4qoz\">99.38 %</td>\n",
    "    <td class=\"tg-r6x4\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yla0\">Facenet</td>\n",
    "    <td class=\"tg-r6x4\">99.20%</td>\n",
    "    <td class=\"tg-r6x4\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yla0\">VGG-Face</td>\n",
    "    <td class=\"tg-r6x4\">98.78%</td>\n",
    "    <td class=\"tg-r6x4\">97.40%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-6t3r\">Human-beings</td>\n",
    "    <td class=\"tg-aznb\">97.53%</td>\n",
    "    <td class=\"tg-r6x4\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yla0\">OpenFace</td>\n",
    "    <td class=\"tg-r6x4\">93.80%</td>\n",
    "    <td class=\"tg-r6x4\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yla0\">DeepID</td>\n",
    "    <td class=\"tg-r6x4\">-</td>\n",
    "    <td class=\"tg-r6x4\">97.05%</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "DeepFace это легковесный фремворк на Python для распознования лиц, анализа атрибутов лица (возраст, гендер, эмоции и расу). Данный опенсорсный фреймворк включает все современные ИИ модели для распознования лиц."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <center><a id=2 >Обзор основных функций библиотеки</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Фукнционал библиотеки:\n",
    "\n",
    "- Верификация лица:  задача сравнения одного лица с другим, для определения один и тот же это человек или нет. Это может быть использовано, например, для проверки лица с фотографией на ID карте. \n",
    "- Распознование лица: Задача включает в себя поиск лица в базе изображений. По сути, происходит верификация лица с каждым изображением в базе данных.\n",
    "- Анализ атрибутов лица. Классификация по гендеру, определение возрасат эмоций и т.д.\n",
    "- Анализ лица в режиме реального времени. Включает в себя распознование лица и анализ характеристик лица в режиме рального времени по видео из вебкамеры. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <center><a id=3 >Верификация лица</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/deepface_3.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта функция проверяет пары лиц на принадлежность одному и тому же человеку или разным людям. Она ожидает точные пути к изображениям в качестве входных данных. Также приветствуется передача изображений в формате numpy или base64. Затем она вернет словарь, и вам нужно будет проверить только его ключ \"verified\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 15:16:13.998950: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-16 15:16:14.516937: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-16 15:16:14.521099: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-16 15:16:16.460001: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path_1 = '../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_105_83.jpeg'\n",
    "test_image_path_2 = '../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_108_84.jpeg'\n",
    "model = 'DeepFace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verified': True,\n",
       " 'distance': 0.30613326489682935,\n",
       " 'threshold': 0.68,\n",
       " 'model': 'VGG-Face',\n",
       " 'detector_backend': 'opencv',\n",
       " 'similarity_metric': 'cosine',\n",
       " 'facial_areas': {'img1': {'x': 7,\n",
       "   'y': 7,\n",
       "   'w': 98,\n",
       "   'h': 98,\n",
       "   'left_eye': (27, 39),\n",
       "   'right_eye': (67, 33)},\n",
       "  'img2': {'x': 22,\n",
       "   'y': 17,\n",
       "   'w': 177,\n",
       "   'h': 177,\n",
       "   'left_eye': None,\n",
       "   'right_eye': None}},\n",
       " 'time': 0.67}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = DeepFace.verify(img1_path = test_image_path_1, img2_path = test_image_path_2)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <center><a id=4 >Распознование лица</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/deepface_4.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распознавание лиц требует многократного применения верификации лица. В этом контексте, библиотека deepface имеет готовую функцию find для выполнения этого действия. Она будет искать идентичность входного изображения в пути к базе данных и вернет список объектов pandas DataFrame в качестве вывода. Тем временем векторы лиц из базы данных хранятся в файле pickle для более быстрого поиска при следующем использовании. Результатом будет размер лиц, появляющихся на исходном изображении. Кроме того, целевые изображения в базе данных также могут содержать множество лиц.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:36:52 - Found 103 newly added image(s), 0 removed image(s), 0 replaced image(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations:   1%|          | 1/103 [00:00<01:14,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:36:53 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_192_136.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_192_136.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations:   3%|▎         | 3/103 [00:01<00:33,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:36:54 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_207_148.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_207_148.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations:  11%|█         | 11/103 [00:03<00:30,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:36:56 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_1_1.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_1_1.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations:  14%|█▎        | 14/103 [00:04<00:26,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:36:57 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_176_125.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_176_125.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations:  18%|█▊        | 19/103 [00:05<00:25,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:36:58 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_203_145.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_203_145.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations:  37%|███▋      | 38/103 [00:12<00:21,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:37:04 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_172_121.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_172_121.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations:  42%|████▏     | 43/103 [00:13<00:18,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:37:06 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_188_133.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_188_133.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations:  45%|████▍     | 46/103 [00:14<00:15,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:37:07 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_315_215.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_315_215.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations:  48%|████▊     | 49/103 [00:15<00:17,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:37:08 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_63_52.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_63_52.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations:  62%|██████▏   | 64/103 [00:19<00:06,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:37:12 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_143_105.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_143_105.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "24-03-16 14:37:12 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_37_32.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_37_32.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "24-03-16 14:37:12 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_226_157.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_226_157.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations:  70%|██████▉   | 72/103 [00:21<00:05,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:37:14 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_36_31.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_36_31.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "24-03-16 14:37:14 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_174_123.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_174_123.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations:  80%|███████▉  | 82/103 [00:24<00:06,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:37:17 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_60_50.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_60_50.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations:  85%|████████▌ | 88/103 [00:26<00:05,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:37:19 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_269_186.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_269_186.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations:  92%|█████████▏| 95/103 [00:28<00:02,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:37:21 - 🔴 Exception while extracting faces from ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_181_127.jpeg: Face could not be detected in ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_181_127.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations: 100%|██████████| 103/103 [00:31<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:37:23 - There are now 103 representations in ds_vggface_opencv_v2.pkl\n",
      "24-03-16 14:37:23 - Searching ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_105_83.jpeg in 103 length datastore\n",
      "24-03-16 14:37:24 - find function duration 31.55146026611328 seconds\n"
     ]
    }
   ],
   "source": [
    "dfs = DeepFace.find(img_path = test_image_path_1, db_path = '../datasets/facescrub/Aaron_Eckhart/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity</th>\n",
       "      <th>hash</th>\n",
       "      <th>target_x</th>\n",
       "      <th>target_y</th>\n",
       "      <th>target_w</th>\n",
       "      <th>target_h</th>\n",
       "      <th>source_x</th>\n",
       "      <th>source_y</th>\n",
       "      <th>source_w</th>\n",
       "      <th>source_h</th>\n",
       "      <th>threshold</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...</td>\n",
       "      <td>15851412c4b2afa2870897adf88990099d16185f</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...</td>\n",
       "      <td>994e38f99f159c90d22bb2bb193e6befff05b03d</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.259117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...</td>\n",
       "      <td>3d251267fb795a383f21f8d0fb7b4d37920f2fde</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.260280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...</td>\n",
       "      <td>13e13e80c90ae525983ac263a47c3c06c6d9042b</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.264468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...</td>\n",
       "      <td>639378aee4daf8e5facc0826214e3c58aa7e480d</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.274597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...</td>\n",
       "      <td>86c408dcc59b4b7fe1f26b4775554da219f6d7bd</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.616485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...</td>\n",
       "      <td>eec9d03bc268374ad97f4bc5be2d78974f253264</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.629791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...</td>\n",
       "      <td>3a5c59e2360ee647fa06a1d5fb6c1d0d1f6f95b5</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>633</td>\n",
       "      <td>633</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.630866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...</td>\n",
       "      <td>a052d2388d75b97259f937436cfcab750597ee94</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.631043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...</td>\n",
       "      <td>b1f052b262347ee30294f31e983e55b36633d917</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.636514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             identity  \\\n",
       "0   ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...   \n",
       "1   ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...   \n",
       "2   ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...   \n",
       "3   ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...   \n",
       "4   ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...   \n",
       "..                                                ...   \n",
       "73  ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...   \n",
       "74  ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...   \n",
       "75  ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...   \n",
       "76  ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...   \n",
       "77  ../datasets/facescrub/Aaron_Eckhart/Aaron_Eckh...   \n",
       "\n",
       "                                        hash  target_x  target_y  target_w  \\\n",
       "0   15851412c4b2afa2870897adf88990099d16185f         7         7        98   \n",
       "1   994e38f99f159c90d22bb2bb193e6befff05b03d        10        11       118   \n",
       "2   3d251267fb795a383f21f8d0fb7b4d37920f2fde        12        11       105   \n",
       "3   13e13e80c90ae525983ac263a47c3c06c6d9042b         9        10       116   \n",
       "4   639378aee4daf8e5facc0826214e3c58aa7e480d        13         9       100   \n",
       "..                                       ...       ...       ...       ...   \n",
       "73  86c408dcc59b4b7fe1f26b4775554da219f6d7bd        10         9        85   \n",
       "74  eec9d03bc268374ad97f4bc5be2d78974f253264        12         9        98   \n",
       "75  3a5c59e2360ee647fa06a1d5fb6c1d0d1f6f95b5        24        39       633   \n",
       "76  a052d2388d75b97259f937436cfcab750597ee94        16        12       151   \n",
       "77  b1f052b262347ee30294f31e983e55b36633d917        17        13       219   \n",
       "\n",
       "    target_h  source_x  source_y  source_w  source_h  threshold  distance  \n",
       "0         98         7         7        98        98       0.68  0.000000  \n",
       "1        118         7         7        98        98       0.68  0.259117  \n",
       "2        105         7         7        98        98       0.68  0.260280  \n",
       "3        116         7         7        98        98       0.68  0.264468  \n",
       "4        100         7         7        98        98       0.68  0.274597  \n",
       "..       ...       ...       ...       ...       ...        ...       ...  \n",
       "73        85         7         7        98        98       0.68  0.616485  \n",
       "74        98         7         7        98        98       0.68  0.629791  \n",
       "75       633         7         7        98        98       0.68  0.630866  \n",
       "76       151         7         7        98        98       0.68  0.631043  \n",
       "77       219         7         7        98        98       0.68  0.636514  \n",
       "\n",
       "[78 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <center><a id=5 >Извлечение признаков embedding</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели распознавания лиц в основном представляют изображения лиц как многомерные векторы. Иногда вам может потребоваться получить эти векторы прямо. DeepFace поставляется с специализированной функцией представления. Функция Represent возвращает список векторов представления. Результатом будет размер лиц, появляющихся в пути к изображению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь вектор представления также отображается с 4096 слотами горизонтально. Каждый слот соответствует значению размерности в векторе представления, а значение размерности объясняется в цветовой шкале справа. Аналогично двумерным штрих-кодам, вертикальная размерность не содержит информации на иллюстрации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/deepface_5.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'embedding': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.02495397046002047,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.07861189855272656,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.04260389946106296,\n",
       "   0.034866325080561034,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03025889809042881,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.001335406025747839,\n",
       "   0.05459277455112479,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.01562894761918541,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.04712544265008249,\n",
       "   0.0,\n",
       "   0.02123350423985391,\n",
       "   0.0,\n",
       "   0.03593599700697382,\n",
       "   0.0,\n",
       "   0.001673738336483814,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.07650152566363479,\n",
       "   0.03367719803883371,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.07515383808322022,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.028147087897365097,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.04585851297549291,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.044099952010663114,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.05213586474112386,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.009634961676040235,\n",
       "   0.026417588338865986,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03522520863814075,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.01718711712207646,\n",
       "   0.0,\n",
       "   0.0011997344917039359,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0029551140770788273,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.014164615977142941,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.01557502672068691,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0029949424301279185,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.009789127804496938,\n",
       "   0.0,\n",
       "   0.013584429162590488,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.06419130069369597,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.010473619377190258,\n",
       "   0.006673921775570277,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.06687328546139873,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03163038674018831,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.014074455707834818,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03299907655823374,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0205019360732904,\n",
       "   0.05624486257988325,\n",
       "   0.0,\n",
       "   0.03753415435965575,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.05504757370488668,\n",
       "   0.03146322926600901,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.011903245505978197,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.10552933134738672,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.052583536040494275,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.017758281676492096,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.04510057468095434,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03154503337268432,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.045704213016436776,\n",
       "   0.03230783112350899,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.008147011072043839,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.025791759790020775,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.014043311677381518,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.014951049800683108,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03169511186242149,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.007337851101644558,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.10033993069031516,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.007684646517273159,\n",
       "   0.0,\n",
       "   0.03294786649324695,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.04742156148982614,\n",
       "   0.0,\n",
       "   0.06077946861316481,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.011160128797551674,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.016985345799436752,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.015592212036290232,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0032513746917040586,\n",
       "   0.02887334683905265,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.07597941766264253,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.06972800581155286,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03345264618155704,\n",
       "   0.0,\n",
       "   0.004834310188672906,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.07130894240491106,\n",
       "   0.10232993181615112,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.02078633159696356,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.08327226868355324,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.036795213899249744,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.030524977766037725,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.022046800736862923,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.009972035123603505,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.034504097591291485,\n",
       "   0.010276637845593111,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.025766162090710913,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.008408453120168446,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.04912211697293104,\n",
       "   0.030343197923898946,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.049339912523781775,\n",
       "   0.0673949632489572,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03470845874991465,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0010037983206965025,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.01890501313983608,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.011231761778670423,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.00825063812180678,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.015468484119372038,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.021418923785418244,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0013043235634812612,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.024398560028222487,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03894487309690799,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.05158958656721564,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.06923857447637174,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0038144214119516244,\n",
       "   0.02701825184622962,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.017349963906537185,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.11313529952746437,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.04507169171542289,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.023582349812957423,\n",
       "   0.0,\n",
       "   0.0014536089999745603,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.05527364108675962,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.02846869199427114,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.07453765022632287,\n",
       "   0.0,\n",
       "   0.056571507018269136,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.012151219551450732,\n",
       "   0.051617462442208925,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.01874014239672098,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.020415140513025443,\n",
       "   0.0,\n",
       "   0.09865941924219315,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.01338492012706989,\n",
       "   0.030464953214447484,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0005962886522891681,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.04468776044729808,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.05231663749272447,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.004645682986412684,\n",
       "   0.003323154642042728,\n",
       "   0.0,\n",
       "   0.06250061567562287,\n",
       "   0.0,\n",
       "   0.030802856533946935,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.019311402282522514,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.06876492904093691,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.029926954204745008,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.04489126117905369,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.020172265474500996,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.00690183100870658,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.023396751826593853,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.027391083118884024,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.005093077458104827,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0016223609832477412,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.01729466559173224,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.04326210157080005,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.010146728054958849,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.02975328241919626,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.014596591819363942,\n",
       "   0.0,\n",
       "   0.004915759247045626,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.053906716121550485,\n",
       "   0.04338609592671985,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.04631531164396407,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.009795831556440914,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.019247790581988687,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.031195362738013203,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.02759119347545411,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0006968887013879807,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.01520870487061293,\n",
       "   ...],\n",
       "  'facial_area': {'x': 7,\n",
       "   'y': 7,\n",
       "   'w': 98,\n",
       "   'h': 98,\n",
       "   'left_eye': (27, 39),\n",
       "   'right_eye': (67, 33)},\n",
       "  'face_confidence': 0.96}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_objs = DeepFace.represent(img_path = test_image_path_1)\n",
    "embedding_objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <center><a id=6 >Анализ аттрибутов лица</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deepface также поставляется с мощным модулем анализа атрибутов лица, включая возраст, пол, выражение лица (включая злость, страх, нейтральность, грусть, отвращение, счастье и удивление) и расовые предположения (включая азиатскую, белую, ближневосточную, индийскую, латиноамериканскую и афроамериканскую). Результатом будет размер лиц, появляющихся на исходном изображении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/deepface_6.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:   0%|          | 0/4 [00:00<?, ?it/s]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  3.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'age': 29,\n",
       "  'region': {'x': 7,\n",
       "   'y': 7,\n",
       "   'w': 98,\n",
       "   'h': 98,\n",
       "   'left_eye': (27, 39),\n",
       "   'right_eye': (67, 33)},\n",
       "  'face_confidence': 0.96,\n",
       "  'gender': {'Woman': 0.002006531576626003, 'Man': 99.99799728393555},\n",
       "  'dominant_gender': 'Man',\n",
       "  'race': {'asian': 0.0067738969736348955,\n",
       "   'indian': 0.04187527146193641,\n",
       "   'black': 0.0008252971457962735,\n",
       "   'white': 90.48247819930054,\n",
       "   'middle eastern': 6.690347992223262,\n",
       "   'latino hispanic': 2.7777041825895528},\n",
       "  'dominant_race': 'white',\n",
       "  'emotion': {'angry': 1.1507914401590824,\n",
       "   'disgust': 0.0014055358406039886,\n",
       "   'fear': 22.164995968341827,\n",
       "   'happy': 12.376193702220917,\n",
       "   'sad': 1.5956517308950424,\n",
       "   'surprise': 0.015635305317118764,\n",
       "   'neutral': 62.69533038139343},\n",
       "  'dominant_emotion': 'neutral'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objs = DeepFace.analyze(img_path = test_image_path_1, \n",
    "        actions = ['age', 'gender', 'race', 'emotion']\n",
    ")\n",
    "objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <center><a id=7 >Детекция лиц</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/deepface_7.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обнаружение лиц и выравнивание являются важными начальными этапами современного конвейера распознавания лиц. Эксперименты показывают, что только выравнивание увеличивает точность распознавания лиц почти на 1%. Deepface содержит обертки для детекторов лиц OpenCV, SSD, Dlib, MTCNN, Faster MTCNN, RetinaFace, MediaPipe, YOLOv8 Face и YuNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 15:16:24.388953: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2024-03-16 15:16:24.652097: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2024-03-16 15:16:24.802617: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2024-03-16 15:16:26.563425: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Dlib is an optional detector, ensure the library is installed.Please install using 'pip install dlib' ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/code/face_recognition/.venvfr/lib/python3.10/site-packages/deepface/detectors/Dlib.py:27\u001b[0m, in \u001b[0;36mDlibClient.build_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdlib\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dlib'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 26\u001b[0m\n\u001b[1;32m     14\u001b[0m obj \u001b[38;5;241m=\u001b[39m DeepFace\u001b[38;5;241m.\u001b[39mverify(img1_path \u001b[38;5;241m=\u001b[39m test_image_path_1, \n\u001b[1;32m     15\u001b[0m         img2_path \u001b[38;5;241m=\u001b[39m test_image_path_2,\n\u001b[1;32m     16\u001b[0m         detector_backend \u001b[38;5;241m=\u001b[39m backends[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#face recognition\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# dfs = DeepFace.find(img_path = test_image_path_1, \u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#         db_path = \"my_db\", \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#embeddings\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m embedding_objs \u001b[38;5;241m=\u001b[39m \u001b[43mDeepFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_image_path_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#facial analysis\u001b[39;00m\n\u001b[1;32m     31\u001b[0m demographies \u001b[38;5;241m=\u001b[39m DeepFace\u001b[38;5;241m.\u001b[39manalyze(img_path \u001b[38;5;241m=\u001b[39m test_image_path_2, \n\u001b[1;32m     32\u001b[0m         detector_backend \u001b[38;5;241m=\u001b[39m backends[\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     33\u001b[0m )\n",
      "File \u001b[0;32m~/code/face_recognition/.venvfr/lib/python3.10/site-packages/deepface/DeepFace.py:367\u001b[0m, in \u001b[0;36mrepresent\u001b[0;34m(img_path, model_name, enforce_detection, detector_backend, align, expand_percentage, normalization)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepresent\u001b[39m(\n\u001b[1;32m    317\u001b[0m     img_path: Union[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[1;32m    318\u001b[0m     model_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVGG-Face\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    323\u001b[0m     normalization: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    324\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    325\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m    Represent facial images as multi-dimensional vector embeddings.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m            to 'skip', the confidence will be 0 and is nonsensical.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepresentation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/face_recognition/.venvfr/lib/python3.10/site-packages/deepface/modules/representation.py:68\u001b[0m, in \u001b[0;36mrepresent\u001b[0;34m(img_path, model_name, enforce_detection, detector_backend, align, expand_percentage, normalization)\u001b[0m\n\u001b[1;32m     66\u001b[0m target_size \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minput_shape\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detector_backend \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 68\u001b[0m     img_objs \u001b[38;5;241m=\u001b[39m \u001b[43mdetection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_faces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# skip\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# Try load. If load error, will raise exception internal\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     img, _ \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mload_image(img_path)\n",
      "File \u001b[0;32m~/code/face_recognition/.venvfr/lib/python3.10/site-packages/deepface/modules/detection.py:89\u001b[0m, in \u001b[0;36mextract_faces\u001b[0;34m(img_path, target_size, detector_backend, enforce_detection, align, expand_percentage, grayscale, human_readable)\u001b[0m\n\u001b[1;32m     87\u001b[0m     face_objs \u001b[38;5;241m=\u001b[39m [DetectedFace(img\u001b[38;5;241m=\u001b[39mimg, facial_area\u001b[38;5;241m=\u001b[39mbase_region, confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)]\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 89\u001b[0m     face_objs \u001b[38;5;241m=\u001b[39m \u001b[43mDetectorWrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_faces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# in case of no face found\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(face_objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m enforce_detection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/code/face_recognition/.venvfr/lib/python3.10/site-packages/deepface/detectors/DetectorWrapper.py:83\u001b[0m, in \u001b[0;36mdetect_faces\u001b[0;34m(detector_backend, img, align, expand_percentage)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect_faces\u001b[39m(\n\u001b[1;32m     60\u001b[0m     detector_backend: \u001b[38;5;28mstr\u001b[39m, img: np\u001b[38;5;241m.\u001b[39mndarray, align: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, expand_percentage: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     61\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[DetectedFace]:\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    Detect face(s) from a given image\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m        - confidence (float): The confidence score associated with the detected face.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m     face_detector: Detector \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# validate expand percentage score\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m expand_percentage \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/code/face_recognition/.venvfr/lib/python3.10/site-packages/deepface/detectors/DetectorWrapper.py:51\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(detector_backend)\u001b[0m\n\u001b[1;32m     48\u001b[0m face_detector \u001b[38;5;241m=\u001b[39m backends\u001b[38;5;241m.\u001b[39mget(detector_backend)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m face_detector:\n\u001b[0;32m---> 51\u001b[0m     face_detector \u001b[38;5;241m=\u001b[39m \u001b[43mface_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     face_detector_obj[detector_backend] \u001b[38;5;241m=\u001b[39m face_detector\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/code/face_recognition/.venvfr/lib/python3.10/site-packages/deepface/detectors/Dlib.py:15\u001b[0m, in \u001b[0;36mDlibClient.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/face_recognition/.venvfr/lib/python3.10/site-packages/deepface/detectors/Dlib.py:29\u001b[0m, in \u001b[0;36mDlibClient.build_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdlib\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDlib is an optional detector, ensure the library is installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install using \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install dlib\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# check required file exists in the home/.deepface/weights folder\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(home \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/.deepface/weights/shape_predictor_5_face_landmarks.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: Dlib is an optional detector, ensure the library is installed.Please install using 'pip install dlib' "
     ]
    }
   ],
   "source": [
    "backends = [\n",
    "  'opencv', \n",
    "  'ssd', \n",
    "  'dlib', \n",
    "  'mtcnn', \n",
    "  'retinaface', \n",
    "  'mediapipe',\n",
    "  'yolov8',\n",
    "  'yunet',\n",
    "  'fastmtcnn',\n",
    "]\n",
    "\n",
    "#face verification\n",
    "obj = DeepFace.verify(img1_path = test_image_path_1, \n",
    "        img2_path = test_image_path_2,\n",
    "        detector_backend = backends[0]\n",
    ")\n",
    "\n",
    "#face recognition\n",
    "# dfs = DeepFace.find(img_path = test_image_path_1, \n",
    "#         db_path = \"my_db\", \n",
    "#         detector_backend = backends[1]\n",
    "# )\n",
    "\n",
    "#embeddings\n",
    "embedding_objs = DeepFace.represent(img_path = test_image_path_1, \n",
    "        detector_backend = backends[2]\n",
    ")\n",
    "\n",
    "#facial analysis\n",
    "demographies = DeepFace.analyze(img_path = test_image_path_2, \n",
    "        detector_backend = backends[3]\n",
    ")\n",
    "\n",
    "#face detection and alignment\n",
    "face_objs = DeepFace.extract_faces(img_path = test_image_path_1, \n",
    "        target_size = (224, 224), \n",
    "        detector_backend = backends[4]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <center><a id=8 >Анализ лица в режиме рального времени</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы также можете использовать Deepface для обработки видео в реальном времени. Функция Stream будет получать доступ к вашей веб-камере и применять как распознавание лиц, так и анализ атрибутов лиц. Функция начнет анализировать кадр, если она сможет сосредоточиться на лице последовательно в течение 5 кадров. Затем она покажет результаты в течение 5 секунд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/deepface_8.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <center><a id=9 >API</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepFace также предоставляет API. Для запуска API вы можете клонировать исходный код DeepFace и запустить API с помощью следующей команды. Это будет использовать сервер gunicorn для создания REST-сервиса. Таким образом, вы сможете вызывать DeepFace из внешней системы, такой как мобильное приложение или веб-приложение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/deepface_9.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd scripts\n",
    "./service.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции распознавания лиц, анализа атрибутов лиц и представления векторов доступны через API. Ожидается, что вы вызываете эти функции как методы HTTP POST. Конечные точки служб по умолчанию будут следующими: http://localhost:5000/verify для распознавания лиц, http://localhost:5000/analyze для анализа атрибутов лиц и http://localhost:5000/represent для представления векторов. Вы можете передавать входные изображения как точные пути к изображениям в вашей среде, закодированные в base64 строки или изображения из Интернета. [Вот ссылка](https://github.com/serengil/deepface/tree/master/deepface/api/postman) на проект Postman, где вы можете узнать, как вызывать эти методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <center><a id=10>Анализ работы библиотеки</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### <center><a id=11>Датасет</a>\n",
    "Для анализа работы библиотеки используется датасет [*Facescrub*](https://www.kaggle.com/search).  \n",
    "Датасет состоит из 5982 изображений с  529 уникальными известными личностями. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "- `Создание датафрейма` :\n",
    "\n",
    "    - `img_path` : путь к файлу\n",
    "    - `class_name` : класс объекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "db_path = '../datasets/facescrub/'\n",
    "\n",
    "\n",
    "def list_images(path):\n",
    "    \"\"\"Create default dict with img paths\"\"\"\n",
    "    imgs_list = []\n",
    "    for dir in os.listdir(path):\n",
    "        full_path = os.path.join(path, dir)\n",
    "        for img_name in os.listdir(full_path):\n",
    "            img_path = os.path.join(full_path, img_name)         \n",
    "            if img_path.endswith('.png') or img_path.endswith('.jpg') or img_path.endswith('.jpeg') :\n",
    "                imgs_list.append((img_path, dir))\n",
    "\n",
    "    return imgs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### <<<<<<<< <a style='color:red'>Создание датафрейма исходных данных</a> >>>>>>>>\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/facescrub/Jack_Nicholson/Jack_Nich...</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/facescrub/Jack_Nicholson/Jack_Nich...</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  labels\n",
       "0  ../datasets/facescrub/Jack_Nicholson/Jack_Nich...     209\n",
       "1  ../datasets/facescrub/Jack_Nicholson/Jack_Nich...     209"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "list_img = list_images(db_path)\n",
    "df = pd.DataFrame(list_img, columns=['img_path', 'class_name'])\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(df['class_name'])\n",
    "df = df.drop(columns='class_name')\n",
    "df['labels'] = labels\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Статистическая` информация о датасете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество всего изображений: 43124\n",
      "Среднее количество изображений на одного человека: 81\n",
      "Минимальное количество изображений на одного человека: 16\n",
      "Максимальное количество изображений на одного человека: 148\n",
      "Количество уникальных людей: 530\n"
     ]
    }
   ],
   "source": [
    "grouped_df = df.groupby(['labels'])['labels'].agg('count')\n",
    "print(\"Количество всего изображений:\", df.shape[0])\n",
    "print(\"Среднее количество изображений на одного человека:\", int(grouped_df.mean()))\n",
    "print(\"Минимальное количество изображений на одного человека:\", int(grouped_df.min()))\n",
    "print(\"Максимальное количество изображений на одного человека:\", int(grouped_df.max()))\n",
    "print(\"Количество уникальных людей:\", int(grouped_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### <center><a id=7>Анализ функций</a>\n",
    "\n",
    "Для анализа функций библиотеки использовались следующие метрики:\n",
    "\n",
    "- `Embedding_time`: Время (сек.) детектирования лица и создания эмбединга для одного изображения\n",
    "\n",
    "- `Macro_recall`: Усредненное значение recall для мультиклассовых задач:\n",
    "    - Рассчитывается значение recall для каждого класса :\n",
    "        - $\\boxed{ \\frac{TP}{TP + FN} }$\n",
    "    - Рассчитывется среднее значение recall из всех классов:\n",
    "        - $\\boxed{ \\frac{1}{n}\\sum_{i=1}^n{(recall_{i})}}$\n",
    "\n",
    "- `Macro_precision`: Усредненное значение precision для мультиклассовых задач:\n",
    "    - Рассчитывается значение precision для каждого класса :\n",
    "        - $\\boxed{\\frac{TP}{TP + FP}}$\n",
    "\n",
    "    - Рассчитывется среднее значение precision из всех классов:\n",
    "        - $\\boxed{ \\frac{1}{n}\\sum_{i=1}^n{(precision_{i})}}$\n",
    "\n",
    "- `Macro_f1`: Усредненное значение F1 для мультиклассовых задач:\n",
    "    - Рассчитывается значение F1 для каждого класса :\n",
    "        - $\\boxed{\\frac{2 \\cdot Precision \\cdot Recall}{Precision + Recall}}$\n",
    "\n",
    "    - Рассчитывется среднее значение F1 из всех классов:\n",
    "        - $\\boxed{ \\frac{1}{n}\\sum_{i=1}^n{(F1{i})}}$\n",
    "\n",
    "- `NaN_count`: Количество недетектированных лиц\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "- `Возвращение эмбедингов` facenet-pytorch:\n",
    "    - df: Датафрейм\n",
    "    - pretrained_weights: Веса предобученной модели\n",
    "        - 'vggface2' \n",
    "        - 'casia-webface'\n",
    "\n",
    "- `Создание столбцов с эмбедингами`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 14:01:11.698989: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-16 14:01:11.888184: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-16 14:01:12.589569: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-16 14:01:14.423690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 14:01:16 - Directory /home/fitlemon/.deepface created\n",
      "24-03-16 14:01:16 - Directory /home/fitlemon/.deepface/weights created\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "from PIL import Image\n",
    "\n",
    "def get_embedding_list(df: pd.DataFrame, model_params: dict) -> list:\n",
    "    model = model_params['model']\n",
    "    backend = model_params['backend']\n",
    "    emb_list = []\n",
    "    for obj_num in range(df.shape[0]):\n",
    "        try:\n",
    "            img_path = df['img_path'][obj_num]\n",
    "            img_embedding = DeepFace.represent(img_path = img_path, model_name=model, detector_backend=backend)\n",
    "            emb_list.append(img_embedding.detach().numpy())\n",
    "        except Exception:\n",
    "            emb_list.append(np.nan)\n",
    "    return emb_list\n",
    "    \n",
    "def get_embedding_column(df: pd.DataFrame, model_params: dict) -> pd.DataFrame:\n",
    "\n",
    "    emb_list  = get_embedding_list(df, model_params)\n",
    "    param_name = list(model_params.values())[0]\n",
    "    df[param_name] = emb_list\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### <<<<<<<< <a style='color:red'>Создание столбца эмбеддингов</a> >>>>>>>>\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>labels</th>\n",
       "      <th>vggface2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/Facescrub/Aaron_Eckhart\\Aaron_Eckhart_105...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.05366709, -0.08842934, 0.0069119674, 0.028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/Facescrub/Aaron_Eckhart\\Aaron_Eckhart_194...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0062582167, -0.11352147, -0.019524956, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/Facescrub/Aaron_Eckhart\\Aaron_Eckhart_274...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.00059679645, -0.10510773, -0.10683876, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  labels  \\\n",
       "0  data/Facescrub/Aaron_Eckhart\\Aaron_Eckhart_105...       0   \n",
       "1  data/Facescrub/Aaron_Eckhart\\Aaron_Eckhart_194...       0   \n",
       "2  data/Facescrub/Aaron_Eckhart\\Aaron_Eckhart_274...       0   \n",
       "\n",
       "                                            vggface2  \n",
       "0  [[0.05366709, -0.08842934, 0.0069119674, 0.028...  \n",
       "1  [[0.0062582167, -0.11352147, -0.019524956, -0....  \n",
       "2  [[0.00059679645, -0.10510773, -0.10683876, -0....  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_example = df[:3]\n",
    "\n",
    "models = [\n",
    "  \"VGG-Face\", \n",
    "  \"Facenet\", \n",
    "  \"Facenet512\", \n",
    "  \"OpenFace\", \n",
    "  \"DeepFace\", \n",
    "  \"DeepID\", \n",
    "  \"ArcFace\", \n",
    "  \"Dlib\", \n",
    "  \"SFace\",\n",
    "]\n",
    "backends = [\n",
    "  'opencv', \n",
    "  'ssd', \n",
    "  'dlib', \n",
    "  'mtcnn', \n",
    "  'retinaface', \n",
    "  'mediapipe',\n",
    "  'yolov8',\n",
    "  'yunet',\n",
    "  'fastmtcnn',\n",
    "]\n",
    "\n",
    "\n",
    "df_example = get_embedding_column(df_example, model_params)\n",
    "df_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Создание датасета с анализом модели`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### <center><a id=8>Сохранение промежуточных данных</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Создание датасета` с эмбедингами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emb = df[:]\n",
    "\n",
    "emb_parameter_list = ['vggface2', 'casia-webface']\n",
    "for emb_parameter in emb_parameter_list:\n",
    "    model_params = {'pretrained': emb_parameter}\n",
    "    df_emb = get_embedding_column(df_emb, model_params)\n",
    "df_emb = df_emb.dropna()\n",
    "df_emb.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Экспорт` датафрейма в pkl-файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "db_path = 'data/Analysis/'\n",
    "df_name = 'df_embedded'\n",
    "pickle.dump(df_emb, open(db_path + df_name + '.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Импорт` датафрейма из pkl-файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>labels</th>\n",
       "      <th>vggface2</th>\n",
       "      <th>casia-webface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/Facescrub/Aaron_Eckhart\\Aaron_Eckhart_105...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.05366709, -0.08842934, 0.0069119674, 0.028...</td>\n",
       "      <td>[[0.0038595798, 0.015715193, 0.0030699784, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  labels  \\\n",
       "0  data/Facescrub/Aaron_Eckhart\\Aaron_Eckhart_105...       0   \n",
       "\n",
       "                                            vggface2  \\\n",
       "0  [[0.05366709, -0.08842934, 0.0069119674, 0.028...   \n",
       "\n",
       "                                       casia-webface  \n",
       "0  [[0.0038595798, 0.015715193, 0.0030699784, -0....  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "db_path = 'data/Analysis/'\n",
    "df_name = 'df_embedded'\n",
    "\n",
    "df_emb = pickle.load(open(db_path + df_name + '.pkl', 'rb'))\n",
    "df_emb.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Удаление объектов` класса количеством < 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5437,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_arr = df_emb['labels'].values\n",
    "for label in labels_arr:\n",
    "    if df_emb[(df_emb['labels'] == label)]['labels'].count() < 7:\n",
    "        df_emb.drop(labels=df_emb[(df_emb['labels'] == label)]['labels'].index, inplace=True)\n",
    "df_emb['labels'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Создание матрицы` из эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def column_to_matrix(df: pd.DataFrame, column: str, array_size: int=512):\n",
    "    col = df.loc[:, column]\n",
    "    matrix = col.to_numpy()[0].reshape(array_size)\n",
    "    for i in range(1, col.shape[0]):\n",
    "        array = col.to_numpy()[i].reshape(array_size)\n",
    "        matrix = np.vstack([matrix , array]) \n",
    "        \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Экспорт` матрицы эмбеддингов в pkl-файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5437, 512)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_casia = column_to_matrix(df_emb, 'casia-webface')\n",
    "\n",
    "db_path = 'data/Analysis/'\n",
    "df_name = 'Matrix_casia'\n",
    "\n",
    "pickle.dump(X_casia, open(db_path + df_name + '.pkl', 'wb'))\n",
    "X_casia.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Импорт` матрицы эмбеддингов из pkl-файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5437, 512), (5437, 512))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_path = 'data/Analysis/'\n",
    "df_name = 'Matrix_vgg'\n",
    "\n",
    "X_vgg = pickle.load(open(db_path + df_name + '.pkl', 'rb'))\n",
    "\n",
    "db_path = 'data/Analysis/'\n",
    "df_name = 'Matrix_casia'\n",
    "\n",
    "X_casia = pickle.load(open(db_path + df_name + '.pkl', 'rb'))\n",
    "X_casia.shape, X_vgg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### <center><a id=9>Датафрейм с результатами анализа</a>\n",
    "\n",
    "Для каждой анализируемой функции библиотеки:\n",
    "- Матрица эмбеддингов и массив целевых классов разбивалась при помощи метода `Stratified k-Fold` на 5 частей, где каждая часть содержит примерно такое же соотношение целевых классов, как и весь исходный массив целевых классов. Тем самым использовались все данные датасета для получения значений метрик.\n",
    "\n",
    "- В качестве алгоритма предсказания класса выбран метод взвешанных k-ближайших соседей (`weighted KNN`), который отдает большее преимущество в выборе класса ближайшим \"соседям\"\n",
    "\n",
    "- Для подбора оптимального количества \"соседей\" для получения наилучших метрик качества (recall, precision, F1) использовался метод `Grid SearchCV`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def analysis_models( \n",
    "                    df: pd.DataFrame,\n",
    "                    target_column: str,\n",
    "                    model_params: dict, \n",
    "                    param_grid: dict, \n",
    "                    df_path: str='data/Analysis/Analysis_facenet.csv',\n",
    "                    get_embedding:bool=False,\n",
    "                    framework:str='Facenet-pytorch',\n",
    "                    min_objects:int=7):\n",
    "    \n",
    "    param_name = list(model_params.values())[0]\n",
    "    \n",
    "######## Столбец с эмбеддингами ########\n",
    "    emb_time = 0\n",
    "    if get_embedding is True:\n",
    "        start_time = time.time()\n",
    "        df = get_embedding_column(df, model_params)\n",
    "        end_time = time.time()\n",
    "        emb_time = round((end_time - start_time) / df.shape[0], 2)\n",
    "        nan_count = df[df[param_name].isna()]['img_path'].count()\n",
    "    print(f'Эмбеддинги {model_params} добавлены в датафрейм > {time.strftime(\"%H : %M\")}')\n",
    "        \n",
    "######## Удаление NaN ########\n",
    "    befor_drop_size = df.shape[0]\n",
    "    df = df.dropna()\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    after_drop_size = df.shape[0]\n",
    "    print(f'Удалено {befor_drop_size - after_drop_size} объектов NaN > {time.strftime(\"%H : %M\")}')\n",
    "\n",
    "######## Удаление объектов с минимальным кол-ом в классе ########\n",
    "    labels_arr = df[target_column].values\n",
    "    for label in labels_arr:\n",
    "        if df[(df[target_column] == label)][target_column].count() < min_objects:\n",
    "            df.drop(labels=df[(df[target_column] == label)][target_column].index, inplace=True)\n",
    "\n",
    "######## Создание матрицы эмбеддингов ########\n",
    "    X = column_to_matrix(df, param_name)\n",
    "    y = df.loc[:, target_column].to_numpy()\n",
    "    print(f'Размер X: {X.shape} размер y: {y.shape} > {time.strftime(\"%H : %M\")}')\n",
    "\n",
    "######## Подбор параметров ########\n",
    "    knn = KNeighborsClassifier(n_jobs=-1, weights='distance')\n",
    "    grid = GridSearchCV(estimator=knn, cv=5, param_grid=param_grid, scoring=['recall_macro', 'precision_macro', 'f1_macro'], refit=False, verbose=1)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    recall = grid.cv_results_['mean_test_recall_macro'].max()\n",
    "    i = grid.cv_results_['mean_test_recall_macro'].argmax()\n",
    "    knn_params_recall = grid.cv_results_['params'][i]\n",
    "\n",
    "    precision = grid.cv_results_['mean_test_precision_macro'].max()\n",
    "    i = grid.cv_results_['mean_test_precision_macro'].argmax()\n",
    "    knn_params_precision = grid.cv_results_['params'][i]\n",
    "\n",
    "    f1 = grid.cv_results_['mean_test_f1_macro'].max()\n",
    "    i = grid.cv_results_['mean_test_f1_macro'].argmax()\n",
    "    knn_params_f1 = grid.cv_results_['params'][i]\n",
    "    \n",
    "######## Создание датафрейма ########\n",
    "    try:\n",
    "        df_analysis = pd.read_csv(df_path)\n",
    "        df_temp = pd.DataFrame(data={'Framework': [framework], 'Parameter': [param_name], 'Embedding_time' : [emb_time], 'Macro_recall' : [recall],  'Macro_precision' : [precision], 'Macro_f1' : [f1], 'KNN_params_recall': [knn_params_recall], 'KNN_params_precision': [knn_params_precision], 'KNN_params_f1': [knn_params_f1], 'NaN_count': [nan_count]} )\n",
    "        df_analysis= pd.concat([df_analysis, df_temp])\n",
    "        print(f'Данные добавлены в датафрейм {df_path} > {time.strftime(\"%H : %M\")}\\n','_'*50)\n",
    "    except Exception:\n",
    "\n",
    "        df_analysis = pd.DataFrame(data={'Framework': [framework], 'Parameter': [param_name], 'Embedding_time' : [emb_time], 'Macro_recall' : [recall],  'Macro_precision' : [precision], 'Macro_f1' : [f1], 'KNN_params_recall': [knn_params_recall], 'KNN_params_precision': [knn_params_precision], 'KNN_params_f1': [knn_params_f1], 'NaN_count': [nan_count]} )\n",
    "        print(f'Создан датафрейм {df_path} > {time.strftime(\"%H : %M\")}\\n','_'*50)\n",
    "    df_analysis.to_csv(df_path, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### <<<<<<<< <a style='color:red'>Создание датафрейма с анализом</a> >>>>>>>>\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df[:100]\n",
    "\n",
    "grid_params = {'n_neighbors': range(1, 7), 'metric': ['cosine', 'l2']}\n",
    "\n",
    "model_params = {'pretrained': 'vggface2'}\n",
    "analysis_models(df=df_analysis, target_column='labels',  model_params=model_params, param_grid=grid_params, get_embedding=True)\n",
    "\n",
    "model_params = {'pretrained': 'casia-webface'}\n",
    "analysis_models(df=df_analysis, target_column='labels',  model_params=model_params, param_grid=grid_params, get_embedding=True)\n",
    "\n",
    "pd.read_csv('data/Analysis/Analysis_facenet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### [К содержанию](#100)\n",
    "____\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
