{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <center>`Анализ библиотеки`<span style='color:red'>FaceRecognition</span>\n",
    "___\n",
    "\n",
    "Ссылки на `документацию`:\n",
    "\n",
    "1. [Репозиторий face_recognition](https://github.com/ageitgey/face_recognition/) \n",
    "2. [Статья по внутренней работе библиотеки face_recognition](https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78)\n",
    "\n",
    "Дополнительные материалы:\n",
    "\n",
    "3. [Face Recognition Pipeline Clearly Explained](https://medium.com/backprop-labs/face-recognition-pipeline-clearly-explained-f57fc0082750)\n",
    "4. [Распознавание лиц: подробное объяснение бумаги \"Arcface\"](https://russianblogs.com/article/51201299672/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a id=100>Содержание</a>\n",
    "- [Краткое описание библиотеки](#1)\n",
    "- [Обзор основных функций библиотеки](#2)\n",
    "    - [Верификация лица](#3)\n",
    "    - [Распознование лица](#4)\n",
    "    - [Анализ признаков embedding](#5)\n",
    "    - [Анализ аттрибутов лица](#6)\n",
    "    - [Детектирование лиц](#7)\n",
    "    - [Анализ лица в режиме реального времени](#8)\n",
    "    - [API](#9)\n",
    "- [Анализ работы библиотеки](#5)\n",
    "    - [Датасет](#6)\n",
    "    - [Анализ функций](#7)\n",
    "    - [Сохранение промежуточных данных](#8)\n",
    "    - [Датафрейм с результатами анализа](#9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <center><a id=1 >Краткое описание библиотеки</a>\n",
    "\n",
    "В библиотеке использованы решения:\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-color:#9ABAD9;border-spacing:0;}\n",
    ".tg td{background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:0px;color:#444;\n",
    "  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{background-color:#409cff;border-color:#9ABAD9;border-style:solid;border-width:0px;color:#fff;\n",
    "  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-fymr{border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-leq3{background-color:#009901;border-color:inherit;font-weight:bold;text-align:center;vertical-align:top}\n",
    ".tg .tg-kbue{background-color:#9aff99;border-color:inherit;font-weight:bold;text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-fymr\">Детектирование</th>\n",
    "    <th class=\"tg-leq3\">Распознование<br></th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-fymr\">OpenCV<br></td>\n",
    "    <td class=\"tg-kbue\">Facenet512</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-fymr\">Ssd</td>\n",
    "    <td class=\"tg-kbue\">SFace</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-fymr\">Dlib<br></td>\n",
    "    <td class=\"tg-kbue\">ArcFace</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-fymr\">MTCNN</td>\n",
    "    <td class=\"tg-kbue\">Dlib</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-fymr\">RetinaFace</td>\n",
    "    <td class=\"tg-kbue\">Facenet</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-fymr\">MediaPipe</td>\n",
    "    <td class=\"tg-kbue\">VGG-Face</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-fymr\">YoloV8</td>\n",
    "    <td class=\"tg-kbue\">OpenFace</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-fymr\">Yunet</td>\n",
    "    <td class=\"tg-kbue\">DeepID</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "Заявленная точность распознования:\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-color:#9ABAD9;border-spacing:0;}\n",
    ".tg td{background-color:#EBF5FF;border-color:#9ABAD9;border-style:solid;border-width:0px;color:#444;\n",
    "  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{background-color:#409cff;border-color:#9ABAD9;border-style:solid;border-width:0px;color:#fff;\n",
    "  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-wa1i{font-weight:bold;text-align:center;vertical-align:middle}\n",
    ".tg .tg-aznb{background-color:#ecf4ff;font-style:italic;text-align:left;vertical-align:top}\n",
    ".tg .tg-gyq4{background-color:#88CDB2;border-color:inherit;color:#062425;font-weight:bold;text-align:center;vertical-align:middle}\n",
    ".tg .tg-4qoz{background-color:#ecf4ff;border-color:inherit;text-align:left;vertical-align:middle}\n",
    ".tg .tg-uzvj{border-color:inherit;font-weight:bold;text-align:center;vertical-align:middle}\n",
    ".tg .tg-g7sd{border-color:inherit;font-weight:bold;text-align:left;vertical-align:middle}\n",
    ".tg .tg-r6x4{background-color:#ecf4ff;text-align:left;vertical-align:middle}\n",
    ".tg .tg-yla0{font-weight:bold;text-align:left;vertical-align:middle}\n",
    ".tg .tg-6t3r{font-style:italic;font-weight:bold;text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-gyq4\">Model</th>\n",
    "    <th class=\"tg-uzvj\">LFW Score</th>\n",
    "    <th class=\"tg-wa1i\">YTF Score</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-g7sd\">Facenet512</td>\n",
    "    <td class=\"tg-4qoz\">99.65%</td>\n",
    "    <td class=\"tg-r6x4\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-g7sd\">SFace</td>\n",
    "    <td class=\"tg-4qoz\">99.60%</td>\n",
    "    <td class=\"tg-r6x4\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-g7sd\">ArcFace</td>\n",
    "    <td class=\"tg-4qoz\">99.41%</td>\n",
    "    <td class=\"tg-r6x4\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-g7sd\">Dlib</td>\n",
    "    <td class=\"tg-4qoz\">99.38 %</td>\n",
    "    <td class=\"tg-r6x4\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yla0\">Facenet</td>\n",
    "    <td class=\"tg-r6x4\">99.20%</td>\n",
    "    <td class=\"tg-r6x4\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yla0\">VGG-Face</td>\n",
    "    <td class=\"tg-r6x4\">98.78%</td>\n",
    "    <td class=\"tg-r6x4\">97.40%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-6t3r\">Human-beings</td>\n",
    "    <td class=\"tg-aznb\">97.53%</td>\n",
    "    <td class=\"tg-r6x4\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yla0\">OpenFace</td>\n",
    "    <td class=\"tg-r6x4\">93.80%</td>\n",
    "    <td class=\"tg-r6x4\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yla0\">DeepID</td>\n",
    "    <td class=\"tg-r6x4\">-</td>\n",
    "    <td class=\"tg-r6x4\">97.05%</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "DeepFace это легковесный фремворк на Python для распознования лиц, анализа атрибутов лица (возраст, гендер, эмоции и расу). Данный опенсорсный фреймворк включает все современные ИИ модели для распознования лиц."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <center><a id=2 >Обзор основных функций библиотеки</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Фукнционал библиотеки:\n",
    "\n",
    "- Верификация лица:  задача сравнения одного лица с другим, для определения один и тот же это человек или нет. Это может быть использовано, например, для проверки лица с фотографией на ID карте. \n",
    "- Распознование лица: Задача включает в себя поиск лица в базе изображений. По сути, происходит верификация лица с каждым изображением в базе данных.\n",
    "- Анализ атрибутов лица. Классификация по гендеру, определение возрасат эмоций и т.д.\n",
    "- Анализ лица в режиме реального времени. Включает в себя распознование лица и анализ характеристик лица в режиме рального времени по видео из вебкамеры. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <center><a id=3 >Верификация лица</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/deepface_3.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта функция проверяет пары лиц на принадлежность одному и тому же человеку или разным людям. Она ожидает точные пути к изображениям в качестве входных данных. Также приветствуется передача изображений в формате numpy или base64. Затем она вернет словарь, и вам нужно будет проверить только его ключ \"verified\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-17 20:40:02.821206: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-17 20:40:03.310715: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-17 20:40:03.310858: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-17 20:40:03.399966: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-17 20:40:03.574086: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-17 20:40:04.405988: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path_1 = '../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_105_83.jpeg'\n",
    "test_image_path_2 = '../datasets/facescrub/Aaron_Eckhart/Aaron_Eckhart_108_84.jpeg'\n",
    "model = 'DeepFace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verified': True,\n",
       " 'distance': 0.32312834177865135,\n",
       " 'threshold': 0.68,\n",
       " 'model': 'VGG-Face',\n",
       " 'detector_backend': 'opencv',\n",
       " 'similarity_metric': 'cosine',\n",
       " 'facial_areas': {'img1': {'x': 7, 'y': 7, 'w': 98, 'h': 98},\n",
       "  'img2': {'x': 22, 'y': 17, 'w': 177, 'h': 177}},\n",
       " 'time': 0.73}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = DeepFace.verify(img1_path = test_image_path_1, img2_path = test_image_path_2)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <center><a id=4 >Распознование лица</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/deepface_4.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распознавание лиц требует многократного применения верификации лица. В этом контексте, библиотека deepface имеет готовую функцию find для выполнения этого действия. Она будет искать идентичность входного изображения в пути к базе данных и вернет список объектов pandas DataFrame в качестве вывода. Тем временем векторы лиц из базы данных хранятся в файле pickle для более быстрого поиска при следующем использовании. Результатом будет размер лиц, появляющихся на исходном изображении. Кроме того, целевые изображения в базе данных также могут содержать множество лиц.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations: 100%|██████████| 103/103 [00:21<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-03-16 22:28:32 - Representations stored in ../datasets/facescrub/Aaron_Eckhart//representations_vgg_face.pkl file.\n",
      "24-03-16 22:28:32 - find function lasts 22.13470149040222 seconds\n"
     ]
    }
   ],
   "source": [
    "dfs = DeepFace.find(img_path = test_image_path_1, db_path = '../datasets/facescrub/Aaron_Eckhart/', enforce_detection=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity</th>\n",
       "      <th>target_x</th>\n",
       "      <th>target_y</th>\n",
       "      <th>target_w</th>\n",
       "      <th>target_h</th>\n",
       "      <th>source_x</th>\n",
       "      <th>source_y</th>\n",
       "      <th>source_w</th>\n",
       "      <th>source_h</th>\n",
       "      <th>threshold</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2.126537e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2.369517e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2.514501e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2.569659e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>6.330052e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>304</td>\n",
       "      <td>304</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>6.442664e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>633</td>\n",
       "      <td>633</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>6.491191e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>6.611069e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>6.729975e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             identity  target_x  target_y  \\\n",
       "0   ../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...         7         7   \n",
       "1   ../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...        12        11   \n",
       "2   ../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...        12        13   \n",
       "3   ../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...        10        11   \n",
       "4   ../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...         9        10   \n",
       "..                                                ...       ...       ...   \n",
       "88  ../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...        38        23   \n",
       "89  ../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...         0         0   \n",
       "90  ../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...        24        39   \n",
       "91  ../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...        16        12   \n",
       "92  ../datasets/facescrub/Aaron_Eckhart//Aaron_Eck...        10         9   \n",
       "\n",
       "    target_w  target_h  source_x  source_y  source_w  source_h  threshold  \\\n",
       "0         98        98         7         7        98        98       0.68   \n",
       "1        105       105         7         7        98        98       0.68   \n",
       "2         88        88         7         7        98        98       0.68   \n",
       "3        118       118         7         7        98        98       0.68   \n",
       "4        116       116         7         7        98        98       0.68   \n",
       "..       ...       ...       ...       ...       ...       ...        ...   \n",
       "88       334       334         7         7        98        98       0.68   \n",
       "89       304       304         7         7        98        98       0.68   \n",
       "90       633       633         7         7        98        98       0.68   \n",
       "91       151       151         7         7        98        98       0.68   \n",
       "92        85        85         7         7        98        98       0.68   \n",
       "\n",
       "        distance  \n",
       "0  -2.220446e-16  \n",
       "1   2.126537e-01  \n",
       "2   2.369517e-01  \n",
       "3   2.514501e-01  \n",
       "4   2.569659e-01  \n",
       "..           ...  \n",
       "88  6.330052e-01  \n",
       "89  6.442664e-01  \n",
       "90  6.491191e-01  \n",
       "91  6.611069e-01  \n",
       "92  6.729975e-01  \n",
       "\n",
       "[93 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <center><a id=5 >Извлечение признаков embedding</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели распознавания лиц в основном представляют изображения лиц как многомерные векторы. Иногда вам может потребоваться получить эти векторы прямо. DeepFace поставляется с специализированной функцией представления. Функция Represent возвращает список векторов представления. Результатом будет размер лиц, появляющихся в пути к изображению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь вектор представления также отображается с 4096 слотами горизонтально. Каждый слот соответствует значению размерности в векторе представления, а значение размерности объясняется в цветовой шкале справа. Аналогично двумерным штрих-кодам, вертикальная размерность не содержит информации на иллюстрации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/deepface_5.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'embedding': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.025636138796655952,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.06896032879738163,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.060386448642201114,\n",
       "   0.016761027518372974,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.029998265593335596,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.023940010218334067,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.010160012455989971,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.030267328896953837,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.04923348514743668,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.04957633184284269,\n",
       "   0.0,\n",
       "   0.011806345768586083,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0718921858906425,\n",
       "   0.0037896455388359753,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.05669414627285061,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.010497127868811611,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03495496586144189,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.006550245744212402,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.013353018753962564,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03268104444379295,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0011985669008977322,\n",
       "   0.03684433112680827,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.008358857305907769,\n",
       "   0.0,\n",
       "   0.03296999398235962,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.028082039457505894,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.009922585165162864,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.056384228356099415,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.008570683756067019,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.020903956072928234,\n",
       "   0.07065382860765965,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03587904700696923,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.01213611038993918,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0444335276445929,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.018506413379110905,\n",
       "   0.06309786475806874,\n",
       "   0.0,\n",
       "   0.04137645570806938,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.040327876206810144,\n",
       "   0.03235902529971198,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.015606349802365608,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.07292805391484748,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.06641706489304212,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.030181587575342443,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0563627732605233,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.012466823739608862,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.009056810045435666,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.022287421846062135,\n",
       "   0.01910244082609566,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.030076955689385704,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.014683979579648778,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03191591235099352,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.010749101709498029,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.08644997225095213,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.014885206337984513,\n",
       "   0.0,\n",
       "   0.01892916572872265,\n",
       "   0.0,\n",
       "   0.02163373074140826,\n",
       "   0.0,\n",
       "   0.06287316438583748,\n",
       "   0.0,\n",
       "   0.037899032890485476,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0025039094369740697,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.013358010695534597,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.031362418321545675,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0297319027065143,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.10255288620715383,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.059673252012794754,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.039242985611621595,\n",
       "   0.0,\n",
       "   0.013887536981755369,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.07250511379608975,\n",
       "   0.08405248638200795,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.08161524286704684,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.049267461480274395,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.028626028909261275,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0239456136449539,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.01145012546282154,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.017936027538463864,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03321832608987248,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03495363912418666,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.042276519697436496,\n",
       "   0.03544033427994826,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03247016239831864,\n",
       "   0.05832953153244446,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.04227697429642153,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.01309660021993881,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0466523462298335,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.009303638146795605,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.015645283487722143,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03457911873862799,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03586924348103118,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.004447818087696218,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.06071810330824741,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.006402227449960156,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.05595984537969354,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.02471006383927579,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.001987294286940577,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.1271708739867877,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.043634505691588776,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.007039737054328937,\n",
       "   0.0,\n",
       "   0.00038960762099749885,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.07203800839767764,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03503757934438454,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.07339764478379732,\n",
       "   0.0,\n",
       "   0.05682576256160356,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03728414823288526,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.017377292032131557,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.026433285528846828,\n",
       "   0.0,\n",
       "   0.07380359673613619,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.010571278151628059,\n",
       "   0.01733322928431348,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.028983640189094145,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.06314500469629906,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0011274771316286017,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.08102155141647702,\n",
       "   0.0,\n",
       "   0.04295065046189014,\n",
       "   0.004333316277172505,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.017102279411361394,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.09135099402597884,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.038361115464242326,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.062419929197762125,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.015566540272768893,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0017553144631630286,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.04001094906549084,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.01600567300972168,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.012279171949334266,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0539153902116787,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.018677877492483765,\n",
       "   0.03835743914201556,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.01377854316912433,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.08040522884252198,\n",
       "   0.05420645215313776,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.011270324152302022,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.06277288577929174,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.03216966752792019,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.001933187742796986,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.013611872110267554,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.02527780855864567,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   ...],\n",
       "  'facial_area': {'x': 7, 'y': 7, 'w': 98, 'h': 98},\n",
       "  'face_confidence': 4.177323981828522}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_objs = DeepFace.represent(img_path = test_image_path_1)\n",
    "embedding_objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <center><a id=6 >Анализ аттрибутов лица</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deepface также поставляется с мощным модулем анализа атрибутов лица, включая возраст, пол, выражение лица (включая злость, страх, нейтральность, грусть, отвращение, счастье и удивление) и расовые предположения (включая азиатскую, белую, ближневосточную, индийскую, латиноамериканскую и афроамериканскую). Результатом будет размер лиц, появляющихся на исходном изображении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/deepface_6.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:04<00:00,  1.05s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'age': 30,\n",
       "  'region': {'x': 7, 'y': 7, 'w': 98, 'h': 98},\n",
       "  'face_confidence': 4.177323981828522,\n",
       "  'gender': {'Woman': 0.004323517350712791, 'Man': 99.9956727027893},\n",
       "  'dominant_gender': 'Man',\n",
       "  'race': {'asian': 0.023384176893159747,\n",
       "   'indian': 0.28760998975485563,\n",
       "   'black': 0.007182724220911041,\n",
       "   'white': 72.5874125957489,\n",
       "   'middle eastern': 19.680458307266235,\n",
       "   'latino hispanic': 7.413958758115768},\n",
       "  'dominant_race': 'white',\n",
       "  'emotion': {'angry': 1.4133674935023484,\n",
       "   'disgust': 0.0015885808389696048,\n",
       "   'fear': 29.113273567752454,\n",
       "   'happy': 7.54844069769625,\n",
       "   'sad': 2.3888701134246655,\n",
       "   'surprise': 0.013009645820238938,\n",
       "   'neutral': 59.52145215996815},\n",
       "  'dominant_emotion': 'neutral'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objs = DeepFace.analyze(img_path = test_image_path_1, \n",
    "        actions = ['age', 'gender', 'race', 'emotion']\n",
    ")\n",
    "objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <center><a id=7 >Детекция лиц</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/deepface_7.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обнаружение лиц и выравнивание являются важными начальными этапами современного конвейера распознавания лиц. Эксперименты показывают, что только выравнивание увеличивает точность распознавания лиц почти на 1%. Deepface содержит обертки для детекторов лиц OpenCV, SSD, Dlib, MTCNN, Faster MTCNN, RetinaFace, MediaPipe, YOLOv8 Face и YuNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  7.74it/s]  \n"
     ]
    }
   ],
   "source": [
    "backends = [\n",
    "  'opencv', \n",
    "  'ssd', \n",
    "  'dlib', \n",
    "  'mtcnn', \n",
    "  'retinaface', \n",
    "  'mediapipe',\n",
    "  'yolov8',\n",
    "  'yunet',\n",
    "  'fastmtcnn',\n",
    "]\n",
    "\n",
    "#face verification\n",
    "obj = DeepFace.verify(img1_path = test_image_path_1, \n",
    "        img2_path = test_image_path_2,\n",
    "        detector_backend = backends[0]\n",
    ")\n",
    "\n",
    "#face recognition\n",
    "# dfs = DeepFace.find(img_path = test_image_path_1, \n",
    "#         db_path = \"my_db\", \n",
    "#         detector_backend = backends[1]\n",
    "# )\n",
    "\n",
    "#embeddings\n",
    "embedding_objs = DeepFace.represent(img_path = test_image_path_1, \n",
    "        detector_backend = backends[2]\n",
    ")\n",
    "\n",
    "#facial analysis\n",
    "demographies = DeepFace.analyze(img_path = test_image_path_2, \n",
    "        detector_backend = backends[3]\n",
    ")\n",
    "\n",
    "#face detection and alignment\n",
    "face_objs = DeepFace.extract_faces(img_path = test_image_path_1, \n",
    "        target_size = (224, 224), \n",
    "        detector_backend = backends[4],\n",
    "        enforce_detection=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <center><a id=8 >Анализ лица в режиме рального времени</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы также можете использовать Deepface для обработки видео в реальном времени. Функция Stream будет получать доступ к вашей веб-камере и применять как распознавание лиц, так и анализ атрибутов лиц. Функция начнет анализировать кадр, если она сможет сосредоточиться на лице последовательно в течение 5 кадров. Затем она покажет результаты в течение 5 секунд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/deepface_8.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <center><a id=9 >API</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepFace также предоставляет API. Для запуска API вы можете клонировать исходный код DeepFace и запустить API с помощью следующей команды. Это будет использовать сервер gunicorn для создания REST-сервиса. Таким образом, вы сможете вызывать DeepFace из внешней системы, такой как мобильное приложение или веб-приложение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../static/img/deepface_9.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd scripts\n",
    "./service.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции распознавания лиц, анализа атрибутов лиц и представления векторов доступны через API. Ожидается, что вы вызываете эти функции как методы HTTP POST. Конечные точки служб по умолчанию будут следующими: http://localhost:5000/verify для распознавания лиц, http://localhost:5000/analyze для анализа атрибутов лиц и http://localhost:5000/represent для представления векторов. Вы можете передавать входные изображения как точные пути к изображениям в вашей среде, закодированные в base64 строки или изображения из Интернета. [Вот ссылка](https://github.com/serengil/deepface/tree/master/deepface/api/postman) на проект Postman, где вы можете узнать, как вызывать эти методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <center><a id=10>Анализ работы библиотеки</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### <center><a id=11>Датасет</a>\n",
    "Для анализа работы библиотеки используется датасет [*Facescrub*](https://www.kaggle.com/search).  \n",
    "Датасет состоит из 5982 изображений с  529 уникальными известными личностями. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "- `Создание датафрейма` :\n",
    "\n",
    "    - `img_path` : путь к файлу\n",
    "    - `class_name` : класс объекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "db_path = '../datasets/lfw/'\n",
    "\n",
    "\n",
    "def list_images(path):\n",
    "    \"\"\"Create default dict with img paths\"\"\"\n",
    "    imgs_list = []\n",
    "    for dir in os.listdir(path):\n",
    "        full_path = os.path.join(path, dir)\n",
    "        for img_name in os.listdir(full_path):\n",
    "            img_path = os.path.join(full_path, img_name)         \n",
    "            if img_path.endswith('.png') or img_path.endswith('.jpg') or img_path.endswith('.jpeg') :\n",
    "                imgs_list.append((img_path, dir))\n",
    "\n",
    "    return imgs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### <<<<<<<< <a style='color:red'>Создание датафрейма исходных данных</a> >>>>>>>>\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/lfw/John_White/John_White_0001.jpg</td>\n",
       "      <td>2785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/lfw/Ross_Verba/Ross_Verba_0001.jpg</td>\n",
       "      <td>4819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         img_path  labels\n",
       "0  ../datasets/lfw/John_White/John_White_0001.jpg    2785\n",
       "1  ../datasets/lfw/Ross_Verba/Ross_Verba_0001.jpg    4819"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "list_img = list_images(db_path)\n",
    "df = pd.DataFrame(list_img, columns=['img_path', 'class_name'])\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(df['class_name'])\n",
    "df = df.drop(columns='class_name')\n",
    "df['labels'] = labels\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### <<<<<<<< <a style='color:red'>Почистим датасет от ошибок, заявленных на странице датасета</a> >>>>>>>>\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13218, 2), (13233, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = ['Debra_Messing_0002', 'Claire_Hentzen_0001', 'Martha_Bowen_0002', \n",
    "    'Sung_Hong_Choi_0001', 'Recep_Tayyip_Erdogan_0004', 'Anja_Paerson_0001', \n",
    "        'Janica_Kostelic_0001', 'Bart_Hendricks_0001', 'Carlos_Beltran_0001', \n",
    "            'Emmy_Rossum_0001', 'Michael_Schumacher_0008', 'Mahmoud_Abbas_0012', \n",
    "            'Andrew_Gilligan_0001', 'Nora_Bendijo_0002', 'Flor_Montulo_0002']\n",
    "\n",
    "cleaned_df = df.copy()\n",
    "for error in errors:\n",
    "    cleaned_df = cleaned_df[~cleaned_df['img_path'].str.contains(error)]\n",
    "cleaned_df.shape, df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### <<<<<<<< <a style='color:red'>Отфильтруем классы и изображения по количеству</a> >>>>>>>>\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/lfw/Jack_Nicholson/Jack_Nicholson_...</td>\n",
       "      <td>2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/lfw/Jack_Nicholson/Jack_Nicholson_...</td>\n",
       "      <td>2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/lfw/Jack_Nicholson/Jack_Nicholson_...</td>\n",
       "      <td>2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../datasets/lfw/Keanu_Reeves/Keanu_Reeves_0008...</td>\n",
       "      <td>3011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../datasets/lfw/Keanu_Reeves/Keanu_Reeves_0003...</td>\n",
       "      <td>3011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  labels\n",
       "0  ../datasets/lfw/Jack_Nicholson/Jack_Nicholson_...    2273\n",
       "1  ../datasets/lfw/Jack_Nicholson/Jack_Nicholson_...    2273\n",
       "2  ../datasets/lfw/Jack_Nicholson/Jack_Nicholson_...    2273\n",
       "3  ../datasets/lfw/Keanu_Reeves/Keanu_Reeves_0008...    3011\n",
       "4  ../datasets/lfw/Keanu_Reeves/Keanu_Reeves_0003...    3011"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['row'] = df.groupby(['labels']).cumcount()\n",
    "df_trimmed = df[df['row'] < 10]\n",
    "labels = (df_trimmed.groupby('labels')['row'].max() > 1).reset_index()\n",
    "indexes = labels[labels['row'] == True].index\n",
    "df_trimmed_full = df_trimmed[df_trimmed['labels'].isin(indexes)].drop(columns=['row']).reset_index(drop=True)\n",
    "df_trimmed_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выберем заранее подготовленный датасет из pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/lfw/Aaron_Peirsol/Aaron_Peirsol_00...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/lfw/Aaron_Peirsol/Aaron_Peirsol_00...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/lfw/Aaron_Peirsol/Aaron_Peirsol_00...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../datasets/lfw/Aaron_Peirsol/Aaron_Peirsol_00...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../datasets/lfw/Abdoulaye_Wade/Abdoulaye_Wade_...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  labels\n",
       "0  ../datasets/lfw/Aaron_Peirsol/Aaron_Peirsol_00...       5\n",
       "1  ../datasets/lfw/Aaron_Peirsol/Aaron_Peirsol_00...       5\n",
       "2  ../datasets/lfw/Aaron_Peirsol/Aaron_Peirsol_00...       5\n",
       "3  ../datasets/lfw/Aaron_Peirsol/Aaron_Peirsol_00...       5\n",
       "4  ../datasets/lfw/Abdoulaye_Wade/Abdoulaye_Wade_...      14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pickle.load(open('data/LFW_trimmed.pkl', 'rb'))\n",
    "df['img_path'] = df['img_path'].apply(lambda x: '../' + x.replace('\\\\', '/').replace('data/', 'datasets/').replace('LFW/', 'lfw/'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Статистическая` информация о датасете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество всего изображений: 4862\n",
      "Среднее количество изображений на одного человека: 5\n",
      "Минимальное количество изображений на одного человека: 3\n",
      "Максимальное количество изображений на одного человека: 10\n",
      "Количество уникальных людей: 901\n"
     ]
    }
   ],
   "source": [
    "grouped_df = df.groupby(['labels'])['labels'].agg('count')\n",
    "print(\"Количество всего изображений:\", df.shape[0])\n",
    "print(\"Среднее количество изображений на одного человека:\", int(grouped_df.mean()))\n",
    "print(\"Минимальное количество изображений на одного человека:\", int(grouped_df.min()))\n",
    "print(\"Максимальное количество изображений на одного человека:\", int(grouped_df.max()))\n",
    "print(\"Количество уникальных людей:\", int(grouped_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### <center><a id=7>Анализ функций</a>\n",
    "\n",
    "Для анализа функций библиотеки использовались следующие метрики:\n",
    "\n",
    "- `Embedding_time`: Время (сек.) детектирования лица и создания эмбединга для одного изображения\n",
    "\n",
    "- `Macro_recall`: Усредненное значение recall для мультиклассовых задач:\n",
    "    - Рассчитывается значение recall для каждого класса :\n",
    "        - $\\boxed{ \\frac{TP}{TP + FN} }$\n",
    "    - Рассчитывется среднее значение recall из всех классов:\n",
    "        - $\\boxed{ \\frac{1}{n}\\sum_{i=1}^n{(recall_{i})}}$\n",
    "\n",
    "- `Macro_precision`: Усредненное значение precision для мультиклассовых задач:\n",
    "    - Рассчитывается значение precision для каждого класса :\n",
    "        - $\\boxed{\\frac{TP}{TP + FP}}$\n",
    "\n",
    "    - Рассчитывется среднее значение precision из всех классов:\n",
    "        - $\\boxed{ \\frac{1}{n}\\sum_{i=1}^n{(precision_{i})}}$\n",
    "\n",
    "- `Macro_f1`: Усредненное значение F1 для мультиклассовых задач:\n",
    "    - Рассчитывается значение F1 для каждого класса :\n",
    "        - $\\boxed{\\frac{2 \\cdot Precision \\cdot Recall}{Precision + Recall}}$\n",
    "\n",
    "    - Рассчитывется среднее значение F1 из всех классов:\n",
    "        - $\\boxed{ \\frac{1}{n}\\sum_{i=1}^n{(F1{i})}}$\n",
    "\n",
    "- `NaN_count`: Количество недетектированных лиц\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "- `Возвращение эмбедингов` facenet-pytorch:\n",
    "    - df: Датафрейм\n",
    "    - pretrained_weights: Веса предобученной модели\n",
    "        - 'vggface2' \n",
    "        - 'casia-webface'\n",
    "\n",
    "- `Создание столбцов с эмбедингами`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "\n",
    "def get_embedding_list(df: pd.DataFrame, model_params: dict) -> list:\n",
    "    df_emb = df.copy()\n",
    "   \n",
    "    model = model_params['model']\n",
    "    backend = model_params['backend']\n",
    "    emb_list = []\n",
    "    progress_bar = tqdm(range(df_emb.shape[0]))\n",
    "    for obj_num in range(df_emb.shape[0]):\n",
    "        try:\n",
    "            img_path = df_emb['img_path'][obj_num]\n",
    "            img_embedding = DeepFace.represent(img_path = img_path, model_name=model, detector_backend=backend)\n",
    "            emb_list.append(np.array(img_embedding[0]['embedding']))\n",
    "        except Exception as err:\n",
    "            emb_list.append(np.nan)\n",
    "        progress_bar.update(1)\n",
    "    return emb_list\n",
    "    \n",
    "def get_embedding_column(df: pd.DataFrame, model_params: dict) -> pd.DataFrame:\n",
    "    df_emb = df.copy()\n",
    "    emb_list  = get_embedding_list(df_emb, model_params)\n",
    "    param_name = f\"{model_params['model']}_{model_params['backend']}\"\n",
    "    df_emb[param_name] = emb_list\n",
    "    \n",
    "    return df_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### <<<<<<<< <a style='color:red'>Создание столбца эмбеддингов</a> >>>>>>>>\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 27.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>labels</th>\n",
       "      <th>VGG-Face_fastmtcnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/lfw/Aaron_Peirsol/Aaron_Peirsol_00...</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.014676366632112157, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/lfw/Aaron_Peirsol/Aaron_Peirsol_00...</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/lfw/Aaron_Peirsol/Aaron_Peirsol_00...</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.000802196440294645...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../datasets/lfw/Aaron_Peirsol/Aaron_Peirsol_00...</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../datasets/lfw/Abdoulaye_Wade/Abdoulaye_Wade_...</td>\n",
       "      <td>14</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  labels  \\\n",
       "0  ../datasets/lfw/Aaron_Peirsol/Aaron_Peirsol_00...       5   \n",
       "1  ../datasets/lfw/Aaron_Peirsol/Aaron_Peirsol_00...       5   \n",
       "2  ../datasets/lfw/Aaron_Peirsol/Aaron_Peirsol_00...       5   \n",
       "3  ../datasets/lfw/Aaron_Peirsol/Aaron_Peirsol_00...       5   \n",
       "4  ../datasets/lfw/Abdoulaye_Wade/Abdoulaye_Wade_...      14   \n",
       "\n",
       "                                  VGG-Face_fastmtcnn  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.014676366632112157, 0.0...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.000802196440294645...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:20<00:00,  1.27it/s]"
     ]
    }
   ],
   "source": [
    "df_example = df[:5]\n",
    "\n",
    "models = [\n",
    "  \"VGG-Face\", \n",
    "  \"Facenet\", \n",
    "  \"Facenet512\", \n",
    "  \"OpenFace\", \n",
    "  \"DeepFace\", \n",
    "  \"DeepID\", \n",
    "  \"ArcFace\", \n",
    "  \"Dlib\", \n",
    "  \"SFace\",\n",
    "]\n",
    "backends = [\n",
    "  'opencv', \n",
    "  'ssd', \n",
    "  'dlib', \n",
    "  'mtcnn', \n",
    "  'retinaface', \n",
    "  'mediapipe',\n",
    "  'yolov8',\n",
    "  'yunet',\n",
    "  'fastmtcnn',\n",
    "]\n",
    "\n",
    "model_params = {'model': models[0], 'backend': backends[8]}\n",
    "df_example = get_embedding_column(df_example, model_params)\n",
    "df_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### <center><a id=8>Сохранение промежуточных данных</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Создание матрицы` из эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def column_to_matrix(df: pd.DataFrame):\n",
    "\n",
    "    col = df.iloc[:, 2]\n",
    "    array_size = col[0].shape[0]\n",
    "    matrix = col.to_numpy()[0].reshape(array_size)\n",
    "    for i in range(1, col.shape[0]):\n",
    "        array = col.to_numpy()[i].reshape(array_size)\n",
    "        matrix = np.vstack([matrix , array]) \n",
    "        \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### <center><a id=9>Датафрейм с результатами анализа</a>\n",
    "\n",
    "Для каждой анализируемой функции библиотеки:\n",
    "- Матрица эмбеддингов и массив целевых классов разбивалась при помощи метода `Stratified k-Fold` на 5 частей, где каждая часть содержит примерно такое же соотношение целевых классов, как и весь исходный массив целевых классов. Тем самым использовались все данные датасета для получения значений метрик.\n",
    "\n",
    "- В качестве алгоритма предсказания класса выбран метод взвешанных k-ближайших соседей (`weighted KNN`), который отдает большее преимущество в выборе класса ближайшим \"соседям\"\n",
    "\n",
    "- Для подбора оптимального количества \"соседей\" для получения наилучших метрик качества (recall, precision, F1) использовался метод `Grid SearchCV`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def analysis_models( \n",
    "                    df: pd.DataFrame,\n",
    "                    model_params: dict, \n",
    "                    param_grid: dict,\n",
    "                    target_column: str='labels',\n",
    "                    framework: str='DeepFace',\n",
    "                    min_objects:int=3, \n",
    "                    df_path: str='data/FC_Analysis.csv',\n",
    "                    get_embedding:bool=False                  \n",
    "                    ):\n",
    "    model = model_params['model']\n",
    "    backend = model_params['backend']\n",
    "    param_name = model + '_' + backend\n",
    "    \n",
    "######## Столбец с эмбеддингами ########\n",
    "    emb_time = 0\n",
    "    if get_embedding is True:\n",
    "        start_time = time.time()\n",
    "        df_emb = get_embedding_column(df, model_params)\n",
    "        end_time = time.time()\n",
    "        emb_time = round((end_time - start_time) / df.shape[0], 2)\n",
    "        nan_count = df_emb[df_emb[param_name].isna()]['img_path'].count()\n",
    "    print(f'Эмбеддинги {model_params} добавлены в датафрейм > {time.strftime(\"%H : %M\")}')\n",
    "        \n",
    "######## Удаление NaN ########\n",
    "    befor_drop_size = df.shape[0]\n",
    "    df_emb = df_emb.dropna()\n",
    "    df_emb.reset_index(inplace=True,drop=True)\n",
    "    after_drop_size = df_emb.shape[0]\n",
    "    print(f'Удалено {befor_drop_size - after_drop_size} объектов NaN > {time.strftime(\"%H : %M\")}')\n",
    "\n",
    "######## Удаление объектов с минимальным кол-ом в классе ########\n",
    "    labels_arr = df_emb[target_column].values\n",
    "    del_count = 0\n",
    "    for label in labels_arr:\n",
    "        if df_emb[(df_emb[target_column] == label)][target_column].count() < min_objects:\n",
    "            del_count += 1\n",
    "            df_emb.drop(labels=df_emb[(df_emb[target_column] == label)][target_column].index, inplace=True)\n",
    "    print(f\"Удалено: {del_count} объектов с кол меньше 3\")\n",
    "######## Создание матрицы эмбеддингов ########\n",
    "    X = column_to_matrix(df_emb)\n",
    "    y = df_emb.loc[:, target_column].to_numpy()\n",
    "    print(f'Размер X: {X.shape} размер y: {y.shape} > {time.strftime(\"%H : %M\")}')\n",
    "\n",
    "######## Подбор параметров ########\n",
    "    knn = KNeighborsClassifier(n_jobs=-1, weights='distance')\n",
    "    grid = GridSearchCV(estimator=knn, cv=5, param_grid=param_grid, scoring=['recall_macro', 'precision_macro', 'f1_macro'], refit=False, verbose=1)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    knn_k1 = KNeighborsClassifier(n_jobs=-1, weights='distance')\n",
    "    grid_k1 = GridSearchCV(estimator=knn_k1, cv=5, param_grid={'n_neighbors': (1,), 'metric': ['cosine', 'l2']}, scoring=['accuracy'], refit=False, verbose=1)\n",
    "    grid_k1.fit(X, y)\n",
    "    \n",
    "    rank_1_accuracy = grid_k1.cv_results_['mean_test_accuracy'].max()\n",
    "    \n",
    "    recall = grid.cv_results_['mean_test_recall_macro'].max()\n",
    "    i = grid.cv_results_['mean_test_recall_macro'].argmax()\n",
    "    knn_params_recall = grid.cv_results_['params'][i]\n",
    "\n",
    "    precision = grid.cv_results_['mean_test_precision_macro'].max()\n",
    "    i = grid.cv_results_['mean_test_precision_macro'].argmax()\n",
    "    knn_params_precision = grid.cv_results_['params'][i]\n",
    "\n",
    "    f1 = grid.cv_results_['mean_test_f1_macro'].max()\n",
    "    i = grid.cv_results_['mean_test_f1_macro'].argmax()\n",
    "    knn_params_f1 = grid.cv_results_['params'][i]\n",
    "    \n",
    "######## Создание датафрейма ########\n",
    "    try:\n",
    "        df_analysis = pd.read_csv(df_path)\n",
    "        df_temp = pd.DataFrame(data={'Framework': [framework], 'Parameter': [param_name], 'Embedding_time' : [emb_time], 'Rank-1-Accuracy': rank_1_accuracy, 'Macro_recall' : [recall],  'Macro_precision' : [precision], 'Macro_f1' : [f1], 'KNN_params_recall': [knn_params_recall], 'KNN_params_precision': [knn_params_precision], 'KNN_params_f1': [knn_params_f1], 'NaN_count': [nan_count], 'Delete_count': [del_count]} )\n",
    "        df_analysis= pd.concat([df_analysis, df_temp])\n",
    "        print(f'Данные добавлены в датафрейм {df_path} > {time.strftime(\"%H : %M\")}\\n','_'*50)\n",
    "    except Exception:\n",
    "\n",
    "        df_analysis = pd.DataFrame(data={'Framework': [framework], 'Parameter': [param_name], 'Embedding_time' : [emb_time], 'Rank-1-Accuracy': rank_1_accuracy, 'Macro_recall' : [recall],  'Macro_precision' : [precision], 'Macro_f1' : [f1], 'KNN_params_recall': [knn_params_recall], 'KNN_params_precision': [knn_params_precision], 'KNN_params_f1': [knn_params_f1], 'NaN_count': [nan_count], 'Delete_count': [del_count]} )\n",
    "        print(f'Создан датафрейм {df_path} > {time.strftime(\"%H : %M\")}\\n','_'*50)\n",
    "    df_analysis.to_csv(df_path, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### <<<<<<<< <a style='color:red'>Создание датафрейма с анализом</a> >>>>>>>>\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_example = df.copy()\n",
    "\n",
    "models = [\n",
    "  \"VGG-Face\",\n",
    "  \"ArcFace\",  \n",
    "  \"Facenet\", \n",
    "  \"Facenet512\",  \n",
    "  \"Dlib\", \n",
    "  \"SFace\", \n",
    "  \"OpenFace\", \n",
    "  \"DeepID\",\n",
    "  \"DeepFace\" \n",
    "]\n",
    "backends = [\n",
    "  'opencv', \n",
    "  'ssd', \n",
    "  'dlib', \n",
    "  'mtcnn', \n",
    "  'retinaface', \n",
    "  'mediapipe',\n",
    "  'yolov8',\n",
    "  'yunet',\n",
    "  'fastmtcnn',\n",
    "]\n",
    "\n",
    "\n",
    "grid_params = {'n_neighbors': (range(1, 4)), 'metric': ['cosine', 'l2']}\n",
    "for model in models[:]:\n",
    "  model_params = {'model': model, 'backend': backends[2]}\n",
    "  analysis_models(df_example, model_params=model_params, param_grid = grid_params, get_embedding=True, df_path='data/FC_Rank1_LFW_Analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### [К содержанию](#100)\n",
    "____\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
